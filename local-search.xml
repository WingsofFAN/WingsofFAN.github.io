<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>caffe(初识2)</title>
    <link href="undefinedundefined/caffe-19-12-04/2019/12/04/"/>
    <url>undefined/caffe-19-12-04/2019/12/04/</url>
    
    <content type="html"><![CDATA[<h1 id="caffe环境配置"><a href="#caffe环境配置" class="headerlink" title="caffe环境配置"></a>caffe环境配置</h1><h2 id="caffe的依赖库简介"><a href="#caffe的依赖库简介" class="headerlink" title="caffe的依赖库简介"></a>caffe的依赖库简介</h2><h3 id="ProtoBuffer"><a href="#ProtoBuffer" class="headerlink" title="ProtoBuffer"></a>ProtoBuffer</h3><p>Google Protocol Buffer (简称ProtoBuf) 是一种轻便高效的结构化数据存储格式，可以用于结构化数据的串行化，或者说序列化。它很合适做数据存储或RPC数据的交换格式。可以用于通信协议、数据存储等领域的语言无关、平台无关、可扩展的序列结构数据格式。<br>要使用Protobuf库，首先需要自己编写一个.proto文件，定义程序中需要处理的结构化数据，在Protobuf中，结构化数据被称为Message。在一个.proto文件中可以定义多喝消息类型。用Protobuf编译器（protoc.exe）将.proto文件编译成目标语言，会生成对应的.h文件和.cc文件，.proto文件中的每一个消息有一个对应的类。<br>Caffe使用起来很简洁，很大程度上是由于Caffe采用了.proto文件作为用户输入的接口。用户通过编写.proto文件定义网路模型和Solver。</p><p><em>简单来说，ProtoBuffer就是caffe保存模型和解析模型用的数据格式。</em></p><h3 id="Boost"><a href="#Boost" class="headerlink" title="Boost"></a>Boost</h3><p>Boost是为C++语言标准库提供扩展的一些C++程序库的总称。Boost库是一个可移植、提供源代码的C++库，作为标准库的后备，是C++标准化进程的开发引擎之一，是为C++语言标准库提供扩展的一些C++程序库的总称。<br>按照实现的功能，Boost可为大致归入下20个分类，在分类中，有些库同时归入几种类别：<br>boost字符串和文本处理库、boost容器库、boost迭代器库、boost算法库、boost函数对象和高阶编程库、boost泛型编程库、boost模板元编程、boost预处理元编程库、boost并发编程库、boost数学和数字库、boost排错和测试库、boost数据结构库、boost图像处理库、boost输入输出库、boost跨语言混合编程库、boost内存管理库、boost解析库、boost编程接口库、boost综合类库、boost编译器问题的变通方案库等。<br>Caffe采用C++作为主开发语言，其中大量的代码依赖于Boost库。</p><p><em>高级的C++库，之后需要学习一下。</em></p><h3 id="GFlags"><a href="#GFlags" class="headerlink" title="GFlags"></a>GFlags</h3><p>GFlags是Google的一个开源的处理命令行参数的库,使用C++开发，可以替代getopt函数。GFlags与getopt函数不同，在GFlags中，标记的定义分散在源码中，不需要列举在一个地方。Caffe库采用GFlags库开发Caffe的命令行。</p><p><em>GFlags在Caffe中主要起到命令行参数解析的作用，这与ProtoBuffer功能类似，只是参数输入源不同。</em></p><h3 id="GLog"><a href="#GLog" class="headerlink" title="GLog"></a>GLog</h3><p>Glog是一个应用程序的日志库，提供基于C++风格的流日志API，以及各种辅助的宏。它的使用方式与C++的stream操作类似。Caffe运行时的日志输出依赖于GLog库，便于开发者根据这些信息决定如何调整参数来控制收敛。</p><h3 id="HDF5"><a href="#HDF5" class="headerlink" title="HDF5"></a>HDF5</h3><p>HDF（Hierarchical Data File）是NCSA为了满足各种领域研究需要而研制的一种高效存储和分发科学数据的新型数据格式。它还可以存储不同类型的图像和数码数据的文件，并且可以在不同类型的机器上传输，同时还有统一处理这种文件根式的函数库。</p><p><em>Caffe训练模型可以选择保存为HDF5格式或（默认的）ProtoBuffer格式</em></p><h3 id="LevelDB-LMDB"><a href="#LevelDB-LMDB" class="headerlink" title="LevelDB LMDB"></a>LevelDB LMDB</h3><p>LMDB(Lighting Memory-Mapped Database Manager),闪电般的内存映射型数据库管理器，在Caffe中的作用主要是提供数据管理，可以将形形色色的原始数据（JPEG图片、二进制数据）转换为统一的Key-Value存储，便于Caffe的DataLayer获取这些数据。LEVELDB库是Caffe早期的版本使用的数据存储方式，由Google开发。它是一种持续的键值对存储方式，键和值可以为任意字节数组。键的存储顺序可由用户定义的比较函数决定。</p><p><em>LMDB已经替代了LEVELDB，但是为了与以前的版本兼容，仍然将这个依赖库编译到Caffe中。</em></p><h3 id="BLAS"><a href="#BLAS" class="headerlink" title="BLAS"></a>BLAS</h3><p>卷积神经网络中用到的数学计算主要是矩阵、向量的计算，Caffe中调用了BLAS(Basic Linear Algebra Subprograms,基本线性代数子程序)中的相应方法。最常见的BLAS实现有IntelMKL、ATLAS、OpenBLAS等，Caffe可以选择其中任一种。</p><p><em>在Makefile.config可以配置选择。</em></p><h2 id="安装实战-ubuntu"><a href="#安装实战-ubuntu" class="headerlink" title="安装实战(ubuntu)"></a>安装实战(ubuntu)</h2><h3 id="依赖库安装"><a href="#依赖库安装" class="headerlink" title="依赖库安装"></a>依赖库安装</h3><h4 id="可以直接用apt-get直接安装的依赖库"><a href="#可以直接用apt-get直接安装的依赖库" class="headerlink" title="可以直接用apt-get直接安装的依赖库"></a>可以直接用apt-get直接安装的依赖库</h4><pre><code>sudo apt-get install gitsudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libboost-all-dev libhdf5-serial-dev python-devsudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev protobuf-compiler openblas-dev</code></pre><h4 id="可能编译安装其他依赖库时会用到的依赖库"><a href="#可能编译安装其他依赖库时会用到的依赖库" class="headerlink" title="可能编译安装其他依赖库时会用到的依赖库"></a>可能编译安装其他依赖库时会用到的依赖库</h4><pre><code>sudo apt-get install -y protobuf-c-compilersudo apt-get install libffi-dev python-dev build-essentialsudo apt-get install autoconf automake libtool</code></pre><h3 id="配置gpu"><a href="#配置gpu" class="headerlink" title="配置gpu"></a>配置gpu</h3><h4 id="安装Nvidia显卡驱动"><a href="#安装Nvidia显卡驱动" class="headerlink" title="安装Nvidia显卡驱动"></a>安装Nvidia显卡驱动</h4><h5 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h5><ul><li><p>查看显卡连接，确认显卡硬件正确连接</p><pre><code>lspci | grep -I nvidia</code></pre></li><li><p>Nvidia官网下载与系统和显卡版本对应的显卡驱动进行安装，不要使用其他辅助安装工具容易出错</p></li></ul><p>删除以前的驱动，防止相互干扰</p><pre><code>sudo apt-get remove --purge nvidia*</code></pre><p>安装一些必要的库</p><pre><code>sudo apt-get updatesudo apt-get install dkms build-essential linux-headers-generic</code></pre><h5 id="禁用nouveau"><a href="#禁用nouveau" class="headerlink" title="禁用nouveau"></a>禁用nouveau</h5><ul><li>打开blacklist.conf, 在最后加入禁用nouveau的设置, 这是一个开源驱动, 如图所示：</li></ul><p>‘’’</p><pre><code>blacklist nouveaublacklist lbm-nouveauoptions nouveau modeset=0alias nouveau offalias lbm-nouveau off</code></pre><p>‘’’</p><ul><li>禁用nouveau内核模块</li></ul><p>‘’’</p><pre><code>echo options nouveau modeset=0sudo update-initramfs -u</code></pre><p>‘’’</p><ul><li><p>检查是否禁用成功，<strong>重启后执行以下命令，若无任何打印内容</strong>，则禁用成功</p><pre><code>lsmod | grep nouveau</code></pre></li></ul><h5 id="安装驱动"><a href="#安装驱动" class="headerlink" title="安装驱动"></a>安装驱动</h5><ul><li><p>首先关闭图形界面</p><pre><code>sudo systemctl set-default multi-user.targetsudo reboot</code></pre></li><li><p>执行从官网下载的.run脚本</p><pre><code>sudo chmod u+x NVIDIA-Linux-x86_64-390.87.run sudo ./NVIDIA-Linux-x86_64-390.87.run </code></pre></li></ul><p>或是视情况而定</p><pre><code>sudo ./NVIDIA-Linux-x86_64-390.87.run –no-opengl-files</code></pre><ul><li><p>若安装失败 则应先卸载已安装部分</p><pre><code>sudo ./NVIDIA-Linux-x86_64-390.87.run –uninstall</code></pre></li><li><p>中间可能会有报错，缺乏各种依赖库<br>若弹出Unable to find a suitable destination to install 32-bit compatibility libraries on Ubuntu 18.04 Bionic Beaver Linux的bug</p><pre><code>sudo dpkg --add-architecture i386sudo apt updatesudo apt install libc6:i386</code></pre></li><li><p>安装完后，执行指令可以查看gpu的状态，则证明</p><pre><code>nvidia-smi</code></pre></li></ul><h4 id="安装cuda"><a href="#安装cuda" class="headerlink" title="安装cuda"></a>安装cuda</h4><ul><li><p>先把前置需要的库安装上</p><pre><code>sudo apt-get install freeglut3-dev libx11-dev libxmu-dev libxi-dev libgl1-mesa-glx libglu1-mesa libglu1-mesa-dev</code></pre></li><li><p>然后从官网上下载，并用md5检查下下载的安装包是否受损</p><pre><code>md5sum cuda_10.0.130_410.48_linux.run</code></pre></li><li><p>开始安装cuda，安装时可以暂时不安装OpenGL</p><pre><code>sudo sh cuda_10.0.130_410.48_linux.run –no-opengl-files</code></pre></li><li><p>添加环境变量</p><pre><code>vim ~/.bashrc</code></pre></li></ul><p>在其中写入<br>‘’’</p><pre><code>export CUDA_HOME=/usr/local/cudaexport PATH=$PATH:$CUDA_HOME/binexport LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}</code></pre><p>‘’’<br>保存后，并执行</p><pre><code>source ~/.bashrc</code></pre><ul><li>查看cuda的版本，判断是否安装成功</li></ul><p>‘’’</p><pre><code>nvcc -V</code></pre><p>‘’’</p><h3 id="编译安装caffe"><a href="#编译安装caffe" class="headerlink" title="编译安装caffe"></a>编译安装caffe</h3><ul><li>先下载源码</li></ul><p>‘’’    </p><pre><code>git clone https//github.com/bvlc/caffe.gitcd caffe/mv Makefile.config.example Makefile.confile</code></pre><p>‘’’</p><pre><code>* 看懂并修改配置文件</code></pre><p>‘’’</p><pre><code># Refer to http://caffe.berkeleyvision.org/installation.html# Contributions simplifying and improving our build system are welcome!# cuDNN acceleration switch (uncomment to build with cuDNN).USE_CUDNN := 1 #使用cudnn，将注释去掉# CPU-only switch (uncomment to build without GPU support).# CPU_ONLY := 1  #使用GPU，所保留注释# uncomment to disable IO dependencies and corresponding data layersUSE_OPENCV := 1     # 使用opencv# USE_LEVELDB := 0USE_LMDB := 1       # 使用LMDB # This code is taken from https://github.com/sh1r0/caffe-android-libUSE_HDF5 := 1       # 使用HDF5# uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)#    You should not set this flag if you will be reading LMDBs with any#    possibility of simultaneous read and write# ALLOW_LMDB_NOLOCK := 1# Uncomment if you&apos;re using OpenCV 3OPENCV_VERSION := 3  # 使用opencv3 以上的版本# To customize your choice of compiler, uncomment and set the following.# N.B. the default for Linux is g++ and the default for OSX is clang++# CUSTOM_CXX := g++# CUDA directory contains bin/ and lib/ directories that we need.CUDA_DIR := /usr/local/cuda     #cuda的安装路径# On Ubuntu 14.04, if cuda tools are installed via# &quot;sudo apt-get install nvidia-cuda-toolkit&quot; then use this instead:# CUDA_DIR := /usr              # 如果是使用 apt-get 安装的，用此路径# CUDA architecture setting: going with all of them.#在不同的cuda版本和gpu上需要使用不同的匹配选项 #具体可以查看官网信息 https://developer.nvidia.com/cuda-gpus# https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities# 将不兼容的选项注释掉# For CUDA &lt; 6.0, comment the *_50 through *_61 lines for compatibility. # For CUDA &lt; 8.0, comment the *_60 and *_61 lines for compatibility.# For CUDA &gt;= 9.0, comment the *_20 and *_21 lines for compatibility.CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \        -gencode arch=compute_20,code=sm_21 \        -gencode arch=compute_30,code=sm_30 \        -gencode arch=compute_35,code=sm_35 \        -gencode arch=compute_50,code=sm_50 \        -gencode arch=compute_52,code=sm_52 \        -gencode arch=compute_60,code=sm_60 \        -gencode arch=compute_61,code=sm_61 \        -gencode arch=compute_61,code=compute_61# BLAS choice:# atlas for ATLAS (default)# mkl for MKL# open for OpenBlasBLAS := atlas  #默认为atlas，也可以选用MKL、ATLAS、OpenBLAS# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.# Leave commented to accept the defaults for your choice of BLAS# (which should work)!  #此处需要手动配置，blas的库目录和引用目录    # BLAS_INCLUDE := /path/to/your/blas# BLAS_LIB := /path/to/your/blas# Homebrew puts openblas in a directory that is not on the standard search path# BLAS_INCLUDE := $(shell brew --prefix openblas)/include# BLAS_LIB := $(shell brew --prefix openblas)/lib# 如果需要安装matlab的接口则需要在此处配置，Matlab相关目录# This is required only if you will compile the matlab interface. # MATLAB directory should contain the mex binary in /bin.# MATLAB_DIR := /usr/local# MATLAB_DIR := /Applications/MATLAB_R2012b.app# python的相关接口，若不使用python2可以将其全部注释掉# NOTE: this is required only if you will compile the python interface.# We need to be able to find Python.h and numpy/arrayobject.h.PYTHON_INCLUDE := /usr/include/python2.7 \        /usr/lib/python2.7/dist-packages/numpy/core/include# Anaconda Python distribution is quite popular. Include path:# Verify anaconda location, sometimes it&apos;s in root.# ANACONDA_HOME := $(HOME)/anaconda# PYTHON_INCLUDE := $(ANACONDA_HOME)/include \        # $(ANACONDA_HOME)/include/python2.7 \        # $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include# 使用python3，在下面几行配置# Uncomment to use Python 3 (default is Python 2)# PYTHON_LIBRARIES := boost_python3 python3.5m# PYTHON_INCLUDE := /usr/include/python3.5m \#                 /usr/lib/python3.5/dist-packages/numpy/core/include# We need to be able to find libpythonX.X.so or .dylib.PYTHON_LIB := /usr/lib# PYTHON_LIB := $(ANACONDA_HOME)/lib# Homebrew installs numpy in a non standard path (keg only)# PYTHON_INCLUDE += $(dir $(shell python -c &apos;import numpy.core; print(numpy.core.__file__)&apos;))/include# PYTHON_LIB += $(shell brew --prefix numpy)/lib# 此处配置建议选上，可以通过python接口来生产caffe模型配置# Uncomment to support layers written in Python (will link against Python libs)# WITH_PYTHON_LAYER := 1# Whatever else you find you need goes here.# 这里需要添加HDF5的相关路径INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial# INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include# LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib# If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies# INCLUDE_DIRS += $(shell brew --prefix)/include# LIBRARY_DIRS += $(shell brew --prefix)/lib# NCCL acceleration switch (uncomment to build with NCCL)# https://github.com/NVIDIA/nccl (last tested version: v1.2.3-1+cuda8.0)# USE_NCCL := 1# Uncomment to use `pkg-config` to specify OpenCV library paths.# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)# USE_PKG_CONFIG := 1# N.B. both build and distribute dirs are cleared on `make clean`BUILD_DIR := buildDISTRIBUTE_DIR := distribute# Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171# DEBUG := 1# The ID of the GPU that &apos;make runtest&apos; will use to run unit tests.TEST_GPUID := 0# enable pretty build (comment to see full commands)Q ?= @CXXFLAGS+=-std=c++11CUSTOM_CXX := g++ -std=c++11</code></pre><p>‘’’</p><ul><li>修改Makefile中的链接库</li></ul><p>将：</p><pre><code>NVCCFLAGS +=-ccbin=$(CXX) -Xcompiler-fPIC $(COMMON_FLAGS)</code></pre><p>替换为：</p><pre><code>NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)</code></pre><p>将：</p><pre><code>LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5</code></pre><p>改为：</p><pre><code>LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial</code></pre><ul><li>开始编译</li></ul><p>‘’’</p><pre><code>makedir buildcd buildcmake ..make -j8make runtest -j8make pycaffe -j8</code></pre><p>‘’’</p><ul><li>安装一下python的依赖</li></ul><p>‘’’</p><pre><code>cd pythonpip install --yes --file requirements.txt</code></pre><p>‘’’</p><h3 id="采坑记录"><a href="#采坑记录" class="headerlink" title="采坑记录"></a>采坑记录</h3>]]></content>
    
    
    <categories>
      
      <category>caffe基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>caffe</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>caffe(初识1)</title>
    <link href="undefinedundefined/caffe-19-12-03/2019/12/03/"/>
    <url>undefined/caffe-19-12-03/2019/12/03/</url>
    
    <content type="html"><![CDATA[<h1 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h1><p>学习框架最基础的就是学该框架如何定义一个神经网络，所以开始先感受一下caffe是如何定义一个网络的。<br>此处为LeNet-5模型运用于minist数据集上时，网络的定义文件。</p><pre><code>name: &quot;LeNet&quot;             //网络的名称layer {                   //定义一个层    name: &quot;mnist&quot;         //层的名称为mnist    type: &quot;Data&quot;          //层的类型为数据层    top: &quot;data&quot;           //层的输出blob有两个： data和label    top: &quot;label&quot;    include {        phase: TRAIN      //该层参数只在训练阶段有效    }    transform_param {        scale: 0.00390625 //数据变换使用的缩放因子    }    data_param {          //数据层参数        source: &quot;examples/mnist/mnist_train_lmdb&quot; //LMDB的路径        batch_size: 64    //批量数目，一次读取64张图        backend: LMDB     //数据格式为LMDB    }}layer {                   //定义一个新的层    name: &quot;mnist&quot;         //名称和上一个层相同，但是参数却不同    type: &quot;Data&quot;    top: &quot;data&quot;    top: &quot;label&quot;    include {        phase: TEST       //且该层参数只在测试阶段使用    }    transform_param {        scale: 0.00390625    }    data_param {        source: &quot;examples/mnist/mnist_train_lmdb&quot;        batch_size: 100        backend: LMDB    }}layer {    name: &quot;conv1&quot;    type: &quot;Convolution&quot;      //该层的类型为卷积层     bottom: &quot;data&quot;           //bottom 为该层的输入接口，    top: &quot;conv1&quot;                 }    param {        lr_mult: 1           //权值（即W）学习速率倍乘因子，“1”表示保持与全局一致     }    param {        lr_mult: 2           //偏置（即B）学习速率倍乘因子，“2”表示在全局参数上乘2    }    convolution_param{       //卷积层参数设置        num_output: 20       //输出通道数        kernel_size: 5       //使用卷积核大小         stride: 1            //卷积步长        weight_filler{            type: &quot;xavier&quot;   //卷积核W初始化方式        }        bias_filler {            type: &quot;constant&quot; //偏置B初始化方式        }    }}layer {    name: &quot;pool1&quot;        type: &quot;Pooling&quot;          //池化层            bottom: &quot;conv1&quot;    top: &quot;pool1&quot;    pooling_param{           //池化层参数设置        pool: MAX            //池化方式        kernel_size: 2        stride: 2    }}layer {    name: &quot;conv2&quot;    type: &quot;Convolution&quot;    bottom: &quot;pool1&quot;    top: &quot;conv2&quot;    param {        lr_mult: 1    }    param {        lr_mult: 2    }    convolution_param {        num_output: 50        kernel_size: 5        stride: 1        weight_filler {            type: &quot;xavier&quot;        }        bias_filler {            type: &quot;constant&quot;        }    }}layer {    name: &quot;pool2&quot;    type: &quot;Pooling&quot;    bottom: &quot;conv2&quot;    top: &quot;pool2&quot;    pooling_param {        pool: MAX        kernel_size: 2        stride: 2    }}layer {    name: &quot;ip1&quot;    type: &quot;InnerProduct&quot;     //全连接层    bottom: &quot;pool2&quot;    top: &quot;ip1&quot;    param {        lr_mult: 1    }    param {        lr_mult: 2    }    inner_product_param {    //全连接层参数设置        num_output: 500      //全连接层输出的元素个数        weght_filler {            type: &quot;xavier&quot;        }        bias_filler {            type: &quot;constant&quot;        }    }}layer {    name: &quot;relu1&quot;           //激活函数relu    type: &quot;ReLU&quot;                 bottom: &quot;ip1&quot;    top: &quot;ip1&quot;}layer {    name: &quot;ip2&quot;    type: &quot;InnerProduct&quot;    bottom: &quot;ip1&quot;    top: &quot;ip2&quot;    param {        lr_mult: 1    }    param {        lr_mult: 2    }    inner_product_param {        num_output: 10        weight_filler {            type: &quot;xavier&quot;        }        bias_filler {            type: &quot;constant&quot;        }    }}layer{                      name: &quot;accuracy&quot;       //准确率层          type: &quot;Accuracy&quot;    bottom: &quot;ip2&quot;          //有两个输入分别为标签label和结果ip2    bottom: &quot;label&quot;        //用于计算分类的准确率    top： &quot;accuracy&quot;    include {        phase: TEST        //只在测试阶段使用    }}layer {     name: &quot;loss&quot;          //损失函数层    type: &quot;SoftmaxWithLoss&quot;   //损失函数计算方式    bottom: &quot;ip2&quot;    bottom: &quot;label&quot;    top： &quot;loss&quot;}</code></pre><ul><li>基本输出接口的名称都和此层的名称相同</li><li>和其他几种框架相比caffe定义层时，不需要指定输入特征图的大小</li></ul><h1 id="训练脚本配置"><a href="#训练脚本配置" class="headerlink" title="训练脚本配置"></a>训练脚本配置</h1><p>训练脚本和超参配置，还是以Lenet5在minist数据集上的例子来做展示。</p><pre><code># 用于训练/预测的网络描述文件（protobuffer 文本格式）即为上一篇中的代码net: &quot;examples/mnist/lenet_train_test.prototxt&quot;# 预测阶段迭代次数。在MNIST下，预测样本组（test batch）大小为100，# 这里设置预测阶段迭代次数为100可以覆盖全部10000张测试集test_iter: 100# 训练时每迭代500次，进行一次预测test_interval: 500# 网络的基础学习速率、冲量和权衰量base_lr: 0.01momentum: 0.9weight_decay: 0.0005# 学习速率的衰减策略lr_policy: &quot;inv&quot;gamma: 0.0001power: 0.75# 每经过100次迭代，在屏幕上打印一次运行LOGdisplay: 100# 最大迭代次数max_iter: 10000# 每5000次迭代打一次快照 存放在 examples/mnist/lenet 目录下snapshot: 5000snapshot_prefix: &quot;examples/mnist/lenet&quot;# Caffe 求解模式为CPU模式。solver_mode: CPU</code></pre><p>至此我们已经很粗略地见识了caffe框架中最重要的两个文件。<br>接下来我们会在实战中，对这两个文件中具体的参数配置和使用进行学习。<br>但在此之前还需要进行一些环境准备和必要知识的了解。</p><hr><blockquote><p>1.caffe 学习资源</p><blockquote><ul><li><a href="http://caffe.berkeleyvision.org/" target="_blank" rel="noopener">官方主页</a></li><li><a href="http://caffecn.cn/" target="_blank" rel="noopener">中文社区</a></li></ul><p>2.Caffe 环境配置（Ubuntu）<br>3.Caffe 数据集制作</p></blockquote></blockquote><hr>]]></content>
    
    
    <categories>
      
      <category>caffe基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>caffe</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Markdown 基础使用简介</title>
    <link href="undefinedundefined/markdown-19-12-02/2019/12/02/"/>
    <url>undefined/markdown-19-12-02/2019/12/02/</url>
    
    <content type="html"><![CDATA[<p><img src="/undefined/markdown-19-12-02/2019/12/02/Markdown.jpg" srcset="/img/loading.gif" alt="Markdown"></p><h1 id="标题设置"><a href="#标题设置" class="headerlink" title="标题设置"></a>标题设置</h1><h2 id="用‘-’设置"><a href="#用‘-’设置" class="headerlink" title="用‘#’设置"></a>用‘#’设置</h2><pre><code># 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题</code></pre><blockquote><h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="六级标题"></a>六级标题</h6></blockquote><h2 id="用‘-’和‘-’设置"><a href="#用‘-’和‘-’设置" class="headerlink" title="用‘-’和‘=’设置"></a>用‘-’和‘=’设置</h2><pre><code>一级标题=====================二级标题---------------------</code></pre><p>只能标记出一级和二级标题</p><h1 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h1><pre><code>*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___</code></pre><blockquote><p><em>斜体文本</em><br><em>斜体文本</em><br><strong>粗体文本</strong><br><strong>粗体文本</strong><br><strong><em>粗斜体文本</em></strong><br><strong><em>粗斜体文本</em></strong>        </p></blockquote><h1 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h1><pre><code>**** * ******- - ----------</code></pre><blockquote><hr><hr><hr><hr><hr></blockquote><h1 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h1><pre><code>没被删除~~被删除~~</code></pre><blockquote><p>没被删除<br><del>被删除</del></p></blockquote><h1 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h1><pre><code>&lt;u&gt;带下划线文本&lt;/u&gt;</code></pre><blockquote><p><u>带下划线文本</u></p></blockquote><h1 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h1><pre><code>你看不懂[^RUNOOB][^RUNOOB]：看不懂，读注释你也看不懂！</code></pre><blockquote><p>你看不懂[^RUNOOB]<br>[^RUNOOB]:看不懂，读注释你也看不懂！</p></blockquote><h1 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h1><pre><code>* 第一项* 第二项* 第三项+ 第一项+ 第二项+ 第三项- 第一项- 第二项- 第三项</code></pre><blockquote><ul><li>第一项</li><li>第二项</li><li>第三项</li></ul><ul><li>第一项</li><li>第二项</li><li>第三项</li></ul><ul><li>第一项</li><li>第二项</li><li>第三项</li></ul></blockquote><h1 id="区块"><a href="#区块" class="headerlink" title="区块"></a>区块</h1><pre><code>&gt;最外层&gt;&gt;第一层嵌套&gt;&gt;&gt;第二层嵌套</code></pre><blockquote><p>最外层</p><blockquote><p>第一层嵌套</p><blockquote><p>第二层嵌套</p></blockquote></blockquote></blockquote><h1 id="代码区块"><a href="#代码区块" class="headerlink" title="代码区块"></a>代码区块</h1><p>在每一行前加上四个空格或制表符（Tab）</p><h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><pre><code>回到[主页](https://wingsoffan.github.io/)回到[主页][Link][Link]:https://wingsoffan.github.io/</code></pre><blockquote><p>回到<a href="https://wingsoffan.github.io/" target="_blank" rel="noopener">主页</a><br>回到[主页][Link]<br>[Link]:<a href="https://wingsoffan.github.io" target="_blank" rel="noopener">https://wingsoffan.github.io</a></p></blockquote><h1 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h1><pre><code>![图片](markdown/fan.jpg)</code></pre><blockquote><p><img src="/undefined/markdown-19-12-02/2019/12/02/fan.jpg" srcset="/img/loading.gif" alt="alt 图片"></p></blockquote><h1 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h1><pre><code>| 左对齐 | 右对齐 | 居中对齐 || :-----| ----: | :----: || 单元格 | 单元格 | 单元格 || 单元格 | 单元格 | 单元格 |</code></pre><blockquote><table><thead><tr><th align="left">左对齐</th><th align="right">右对齐</th><th align="center">居中对齐</th></tr></thead><tbody><tr><td align="left">单元格</td><td align="right">单元格</td><td align="center">单元格</td></tr><tr><td align="left">单元格</td><td align="right">单元格</td><td align="center">单元格</td></tr></tbody></table></blockquote>]]></content>
    
    
    <categories>
      
      <category>blog入门</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="undefinedundefined/hello-world/2019/11/30/"/>
    <url>undefined/hello-world/2019/11/30/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo server</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo generate</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>